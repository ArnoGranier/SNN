\documentclass[12pt]{scrartcl}

\usepackage[english, francais]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{graphicx, caption}
\usepackage{amssymb}
\usepackage{graphics, caption}
\usepackage{mathtools, bm}
\usepackage{hyperref}
\usepackage{xlop}
\usepackage{changepage}
\usepackage{tabvar}
\usepackage{afterpage}
\usepackage{amsmath}
\usepackage{bbold}
\usepackage{slashbox}
\usepackage{apacite}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{color}
\usepackage{url}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\fnb}{T1}{txtt}{bx}{n}{10} % for bold

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

% Python style for highlighting
\lstset{
language=Python,
basicstyle=\ttfamily,
otherkeywords={self}, % Add keywords here
keywordstyle=\ttb\color{deepblue},
stringstyle=\color{deepgreen},
commentstyle=\color{deepred},
frame=tb, % Any extra options here
showstringspaces=false % 
}
\usepackage{empheq}

\title{Synopsis TER}
\subtitle{Modélisation mathématique et informatique de neurones : création d'une bibliothèque Python/Tensorflow (BRNN - Biologicaly realstic neural network) pour la simulation de réseaux de spiking-neurons et applications}
\author{Granier Arno \\ encadré par C.Shlick et B.Ainseba}

\begin{document}

\maketitle

\tableofcontents

\pagebreak

\section{Introduction} Présentation du sujet, approches prisent et définitions. Intérêts scientifiques, notamment comparaison sous plusieurs angles de vues des réseaux de neurones formels et des réseaux proposés ici. Aspects philosophiques.


\section{Modélisation d'un neurone}\label{mod1}

\subsection{Rappel sur les aspects neurobiologiques} Neurones, synapses. PPSE, PPSI, potentiel d'action, dynamique des potentiels d'actions -mécanismes chimiques et dynamiques temporelles.

\subsection{Limites des neurones formels} Présentation des neurones formels et justification de ce modèle. Limites de ce modèle, notamment l'absence d'une composante temporelle dans les comportements de ce modèle. Ces limites justifient que l'on n'utilise pas les neurones formels dans le but de modéliser des neurones biologiques. Besoin de la théorie des systèmes dynamiques.

\subsection{Integrate and fire - Leaky Integrate and fire} Présentation des modèles. Passage de Integrate and fire à Integrate and fire avec période refractaire à Leaky Integrate and fire. Comparaison avec données électrophysiologiques. Mise en évidence des limites et du non réalisme de ces modèles. Présentation et commentaire d'une implémentation en Python.

\subsection{Modèle de Hodgkin-Huxhkley} Présentation complète du modèle - modèle en circuit RC mis en relation avec les mécanisme neuro-électriques et neurochimique, explication des dynamiques d'inactivation et d'activation des canaux ioniques, explication du comportement du modèle, notamment explication du rôle des constantes temporelles (m,h,n). Réalisme biologique mais problème en termes de complexité de computation. Présentation et commentaire d'une implémentation en Python. Discussion autour des deux approches possibles pour travailler à partir de Hodgkin-Huxley : complexifier ou simplifier. Résumé rapide des approches où on complexifie - Cable Theory, modèles multi-compartimentaux. Dans la suite on s'intéressera aux simplifications de Hodgkin-Huxkley, dans des soucis d'implémentation de réseaux de grandes tailles.

\subsection{Modèle de FitzHugh-Nagumo} Explication de la réduction à partir de Hodgkin-Huxley. Etude à partir de la théorie des systèmes dynamiques : points fixes, isoclines, plan de phase, dynamiques, diagrammes de bifurcation.

\subsection{Modèle de Izhikeviech} Explication de la réduction à partir de Hodgkin-Huxley. Etude à partir de la théorie des systèmes dynamiques : points fixe, isoclines, plan de phase, dynamiques, diagrammes de bifurcation.

\subsection{Modèle par processus de Poisson} 

\subsection{Implémentations supplémentaires conditionnelles au fait que le reste soit fait} Adaptation des modèles simples à des données électrophysiologiques : introduction des méthodes de Spike-trigerred average avec bruit blanc gaussien, analyse en composante principales, divergence de Kullback-Leibler, adaptation aux données d'un neurones modélisés par un processus de Poisson.


\section{Modélisation de réseaux de neurones}\label{modr}

\subsection{Modèle de synapses entre deux neurones pour un spike} A partir du modèle en circuit RC, à partir de Hodgkin-Huxley. Différents types de synapses : fonctions alpha, délais. Présentation d'une implémentation en Python.

\subsection{Generalisation à plusieurs spikes} Filtre linéaire pour intégrer plusieurs spikes

\subsection{Generalisation à plus de deux neurones}

\subsection{Modèles et architectures de réseaux} Feedforward, recurrent. Présentations et commentaires de plusieurs implémentation en Python-Tensorflow.

\subsection{Apprentissage} Règle de Hebb, règle de Oja. Spike-timing dependent synaptic plasticity. Présentation d'une implémentation en Python.

\subsection{Implémentations supplémentaires conditionnelles au fait que le reste soit fait} Apprentissage non-supervisé - apprentissage par compétition, Algorithme EM. Apprentissage supervisé. Apprentissage par renforcement. Reste à voir si la réalité biologique permet d'implémenter ce genre d'algorithme, puisque le but de ce TER est de rester proche de la réalité biologique. On pourra étudier les modèles des ganglions de la base en relation avec l'apprentissage par renforcement.


\section{En ce qui concerne la partie informatique}

Tout ce qui a été présenté dans \ref{mod1} et \ref{modr} sera implémenté dans une bibliothèque Python 3+ / Tensorflow. Pour ce qui est de la simulation d'un seul neurone, tensorflow ne devrait pas être nécessaire et on s'intéressera plutôt aux différents ODE solver disponible dans Python (scipy et autres). Pour ce qui est de l'implémentation des réseaux, on essayera d'utiliser au maximum les outils de tensorflow pour obtenir une implémentation rapide. En plus de l'implémentation des modèles, on aura également une grosse partie affichage et visualisation de données (euler plot, isoclines, plans de phase, raster plot, affichage du comportement d'un ou plusieurs neurones dans un réseau, etc ..), certainement basée sur matplotlib. Si l'usage de Tensorflow se révèle excessif, on ne l'utilisera pas. Tout sera accompagné d'une documentation "technique", bien sur.


\section{Applications concrètes et applications futures envisageables}

Pour des applications plus concrètes, et en utilisant l'outil qu'on aura mis en place, on pourra présenter les propriétés générales des réseaux qu'on retrouve dans un réseau du type présenté dans \cite{izhi2003} ou \cite{brette2007}. On pourra reproduire le modèle des ganglions de la base de \cite{garenne2016}. Dans un registre plus clinique on pourra s'intéresser à un modèle de la maladie de Parkinson (proposé par M.Ainseba, pour l'instant moi je sais pas précisement comment on ferrai ça). Enfin pour conclure on pourra parler des applications futures possibles de ce type de réseaux de neurones, notamment au niveau de l'implémentation possible de la simulation d'un cerveau entier en temps réel (ou proche de réel), et des implications -cartographie du cerveau du vers C.Elegans, fonctionnalisme. Notamment, est-ce qu'on verrait l'apparition d'un phénomène similaire à la conscience ? (c'est une ouverture interrogative, je compte pas répondre à la question [enfin si, plus tard]).


\section{Notes}

La bibliographie est temporaire et incomplète, elle sera étoffée au fur et à mesure du TER.
\nocite{*}

\pagebreak
\bibliographystyle{apacite}
\bibliography{ref}




\end{document}

